import numpy as np
import tflite_runtime.interpreter as tflite
from PIL import Image, ImageEnhance
import os
import time

# Load labels
with open("labelmap.txt", "r") as f:
    labels = f.read().splitlines()

# Load model
interpreter = tflite.Interpreter(model_path="model.tflite")
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

input_height = input_details[0]['shape'][1]
input_width = input_details[0]['shape'][2]

def detect_image(image_path):
    # Load and process the image
    img = Image.open(image_path).convert('RGB')

    # Flip the image 180 degrees (in case camera is upside down)
    img = img.rotate(180)

    # Resize to model's expected size
    img = img.resize((input_width, input_height))

    # Increase sharpness to improve recognition (optional)
    enhancer = ImageEnhance.Sharpness(img)
    img = enhancer.enhance(2)  # Adjust sharpness

    input_data = np.expand_dims(np.array(img, dtype=np.uint8), axis=0)

    # Inference
    interpreter.set_tensor(input_details[0]['index'], input_data)
    interpreter.invoke()

    boxes = interpreter.get_tensor(output_details[0]['index'])[0]
    classes = interpreter.get_tensor(output_details[1]['index'])[0]
    scores = interpreter.get_tensor(output_details[2]['index'])[0]

    for i in range(len(scores)):
        if scores[i] > 0.5:
            label = labels[int(classes[i])]
            print(f"Detected: {label} ({scores[i]*100:.1f}%)")
            if label == 'person':
                print("✅ Person detected → Helmet likely ON.")
                return True
    print("❌ No person detected.")
    return False

# Main loop
while True:
    os.system("libcamera-still -o image.jpg --width 320 --height 240 -n -t 100")
    detect_image("image.jpg")
    time.sleep(2)
